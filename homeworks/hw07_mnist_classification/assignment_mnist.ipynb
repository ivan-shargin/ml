{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №7\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_mnist_data = MNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "print(_image.shape)\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "plt.show()\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = nn.Softmax(dim=1)\n",
    "x = torch.ones((5, 3))\n",
    "sfm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "#         self.sfm = self.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_f = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x_f)\n",
    "#         probas = self.sof\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model = FCNetwork()  # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, \"Please, use `model` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте параметры модели на обучающей выборке. Рекомендуем поработать с различными оптимизаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss:{test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------\n",
      "loss: 2.292557 [   32/60000]\n",
      "loss: 0.621755 [ 3232/60000]\n",
      "loss: 0.510474 [ 6432/60000]\n",
      "loss: 0.262927 [ 9632/60000]\n",
      "loss: 0.309801 [12832/60000]\n",
      "loss: 0.136081 [16032/60000]\n",
      "loss: 0.033521 [19232/60000]\n",
      "loss: 0.413048 [22432/60000]\n",
      "loss: 0.360634 [25632/60000]\n",
      "loss: 0.298716 [28832/60000]\n",
      "loss: 0.482359 [32032/60000]\n",
      "loss: 0.064129 [35232/60000]\n",
      "loss: 0.117424 [38432/60000]\n",
      "loss: 0.024481 [41632/60000]\n",
      "loss: 0.207020 [44832/60000]\n",
      "loss: 0.447086 [48032/60000]\n",
      "loss: 0.101452 [51232/60000]\n",
      "loss: 0.057341 [54432/60000]\n",
      "loss: 0.229086 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss:0.116189 \n",
      "\n",
      "Epoch 2\n",
      "---------------------\n",
      "loss: 0.052052 [   32/60000]\n",
      "loss: 0.013722 [ 3232/60000]\n",
      "loss: 0.069008 [ 6432/60000]\n",
      "loss: 0.034473 [ 9632/60000]\n",
      "loss: 0.015256 [12832/60000]\n",
      "loss: 0.089099 [16032/60000]\n",
      "loss: 0.007761 [19232/60000]\n",
      "loss: 0.174310 [22432/60000]\n",
      "loss: 0.281592 [25632/60000]\n",
      "loss: 0.356272 [28832/60000]\n",
      "loss: 0.068718 [32032/60000]\n",
      "loss: 0.056515 [35232/60000]\n",
      "loss: 0.124894 [38432/60000]\n",
      "loss: 0.021863 [41632/60000]\n",
      "loss: 0.059997 [44832/60000]\n",
      "loss: 0.091928 [48032/60000]\n",
      "loss: 0.082297 [51232/60000]\n",
      "loss: 0.157792 [54432/60000]\n",
      "loss: 0.050837 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss:0.097309 \n",
      "\n",
      "Epoch 3\n",
      "---------------------\n",
      "loss: 0.056671 [   32/60000]\n",
      "loss: 0.037508 [ 3232/60000]\n",
      "loss: 0.027298 [ 6432/60000]\n",
      "loss: 0.187893 [ 9632/60000]\n",
      "loss: 0.017339 [12832/60000]\n",
      "loss: 0.010185 [16032/60000]\n",
      "loss: 0.008562 [19232/60000]\n",
      "loss: 0.021256 [22432/60000]\n",
      "loss: 0.032158 [25632/60000]\n",
      "loss: 0.009227 [28832/60000]\n",
      "loss: 0.004013 [32032/60000]\n",
      "loss: 0.004186 [35232/60000]\n",
      "loss: 0.097996 [38432/60000]\n",
      "loss: 0.042453 [41632/60000]\n",
      "loss: 0.022204 [44832/60000]\n",
      "loss: 0.085865 [48032/60000]\n",
      "loss: 0.031039 [51232/60000]\n",
      "loss: 0.115731 [54432/60000]\n",
      "loss: 0.010705 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss:0.108931 \n",
      "\n",
      "Epoch 4\n",
      "---------------------\n",
      "loss: 0.007809 [   32/60000]\n",
      "loss: 0.003012 [ 3232/60000]\n",
      "loss: 0.021231 [ 6432/60000]\n",
      "loss: 0.001818 [ 9632/60000]\n",
      "loss: 0.136812 [12832/60000]\n",
      "loss: 0.003229 [16032/60000]\n",
      "loss: 0.026497 [19232/60000]\n",
      "loss: 0.131756 [22432/60000]\n",
      "loss: 0.004181 [25632/60000]\n",
      "loss: 0.093017 [28832/60000]\n",
      "loss: 0.006419 [32032/60000]\n",
      "loss: 0.108073 [35232/60000]\n",
      "loss: 0.200302 [38432/60000]\n",
      "loss: 0.023981 [41632/60000]\n",
      "loss: 0.087155 [44832/60000]\n",
      "loss: 0.012041 [48032/60000]\n",
      "loss: 0.059600 [51232/60000]\n",
      "loss: 0.075261 [54432/60000]\n",
      "loss: 0.094493 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss:0.076649 \n",
      "\n",
      "Epoch 5\n",
      "---------------------\n",
      "loss: 0.014996 [   32/60000]\n",
      "loss: 0.032595 [ 3232/60000]\n",
      "loss: 0.046604 [ 6432/60000]\n",
      "loss: 0.003002 [ 9632/60000]\n",
      "loss: 0.094309 [12832/60000]\n",
      "loss: 0.002878 [16032/60000]\n",
      "loss: 0.001847 [19232/60000]\n",
      "loss: 0.041915 [22432/60000]\n",
      "loss: 0.088661 [25632/60000]\n",
      "loss: 0.027025 [28832/60000]\n",
      "loss: 0.002086 [32032/60000]\n",
      "loss: 0.028056 [35232/60000]\n",
      "loss: 0.014982 [38432/60000]\n",
      "loss: 0.001293 [41632/60000]\n",
      "loss: 0.063105 [44832/60000]\n",
      "loss: 0.134791 [48032/60000]\n",
      "loss: 0.126942 [51232/60000]\n",
      "loss: 0.073871 [54432/60000]\n",
      "loss: 0.008279 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss:0.080429 \n",
      "\n",
      "Epoch 6\n",
      "---------------------\n",
      "loss: 0.033531 [   32/60000]\n",
      "loss: 0.008621 [ 3232/60000]\n",
      "loss: 0.192166 [ 6432/60000]\n",
      "loss: 0.007941 [ 9632/60000]\n",
      "loss: 0.009157 [12832/60000]\n",
      "loss: 0.003981 [16032/60000]\n",
      "loss: 0.013146 [19232/60000]\n",
      "loss: 0.002442 [22432/60000]\n",
      "loss: 0.001035 [25632/60000]\n",
      "loss: 0.034418 [28832/60000]\n",
      "loss: 0.000403 [32032/60000]\n",
      "loss: 0.005564 [35232/60000]\n",
      "loss: 0.160700 [38432/60000]\n",
      "loss: 0.000794 [41632/60000]\n",
      "loss: 0.000693 [44832/60000]\n",
      "loss: 0.007470 [48032/60000]\n",
      "loss: 0.007294 [51232/60000]\n",
      "loss: 0.001432 [54432/60000]\n",
      "loss: 0.000776 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss:0.097366 \n",
      "\n",
      "Epoch 7\n",
      "---------------------\n",
      "loss: 0.005673 [   32/60000]\n",
      "loss: 0.007630 [ 3232/60000]\n",
      "loss: 0.028642 [ 6432/60000]\n",
      "loss: 0.000340 [ 9632/60000]\n",
      "loss: 0.008207 [12832/60000]\n",
      "loss: 0.013585 [16032/60000]\n",
      "loss: 0.000918 [19232/60000]\n",
      "loss: 0.099074 [22432/60000]\n",
      "loss: 0.000846 [25632/60000]\n",
      "loss: 0.021219 [28832/60000]\n",
      "loss: 0.003207 [32032/60000]\n",
      "loss: 0.001528 [35232/60000]\n",
      "loss: 0.222457 [38432/60000]\n",
      "loss: 0.121425 [41632/60000]\n",
      "loss: 0.000867 [44832/60000]\n",
      "loss: 0.000684 [48032/60000]\n",
      "loss: 0.100746 [51232/60000]\n",
      "loss: 0.001104 [54432/60000]\n",
      "loss: 0.247254 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss:0.090537 \n",
      "\n",
      "Epoch 8\n",
      "---------------------\n",
      "loss: 0.016790 [   32/60000]\n",
      "loss: 0.003095 [ 3232/60000]\n",
      "loss: 0.022782 [ 6432/60000]\n",
      "loss: 0.001832 [ 9632/60000]\n",
      "loss: 0.000922 [12832/60000]\n",
      "loss: 0.000286 [16032/60000]\n",
      "loss: 0.000443 [19232/60000]\n",
      "loss: 0.000615 [22432/60000]\n",
      "loss: 0.033768 [25632/60000]\n",
      "loss: 0.004632 [28832/60000]\n",
      "loss: 0.105301 [32032/60000]\n",
      "loss: 0.011625 [35232/60000]\n",
      "loss: 0.003573 [38432/60000]\n",
      "loss: 0.001240 [41632/60000]\n",
      "loss: 0.001759 [44832/60000]\n",
      "loss: 0.031272 [48032/60000]\n",
      "loss: 0.016586 [51232/60000]\n",
      "loss: 0.020505 [54432/60000]\n",
      "loss: 0.108302 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss:0.131590 \n",
      "\n",
      "Epoch 9\n",
      "---------------------\n",
      "loss: 0.003903 [   32/60000]\n",
      "loss: 0.029469 [ 3232/60000]\n",
      "loss: 0.051924 [ 6432/60000]\n",
      "loss: 0.023803 [ 9632/60000]\n",
      "loss: 0.281517 [12832/60000]\n",
      "loss: 0.002391 [16032/60000]\n",
      "loss: 0.000945 [19232/60000]\n",
      "loss: 0.153595 [22432/60000]\n",
      "loss: 0.000464 [25632/60000]\n",
      "loss: 0.000737 [28832/60000]\n",
      "loss: 0.062709 [32032/60000]\n",
      "loss: 0.000321 [35232/60000]\n",
      "loss: 0.008776 [38432/60000]\n",
      "loss: 0.153849 [41632/60000]\n",
      "loss: 0.005000 [44832/60000]\n",
      "loss: 0.000104 [48032/60000]\n",
      "loss: 0.000184 [51232/60000]\n",
      "loss: 0.000789 [54432/60000]\n",
      "loss: 0.034438 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss:0.090023 \n",
      "\n",
      "Epoch 10\n",
      "---------------------\n",
      "loss: 0.015849 [   32/60000]\n",
      "loss: 0.017847 [ 3232/60000]\n",
      "loss: 0.002239 [ 6432/60000]\n",
      "loss: 0.002736 [ 9632/60000]\n",
      "loss: 0.001368 [12832/60000]\n",
      "loss: 0.001121 [16032/60000]\n",
      "loss: 0.005908 [19232/60000]\n",
      "loss: 0.006827 [22432/60000]\n",
      "loss: 0.000753 [25632/60000]\n",
      "loss: 0.000537 [28832/60000]\n",
      "loss: 0.015593 [32032/60000]\n",
      "loss: 0.018315 [35232/60000]\n",
      "loss: 0.000242 [38432/60000]\n",
      "loss: 0.022566 [41632/60000]\n",
      "loss: 0.029061 [44832/60000]\n",
      "loss: 0.087456 [48032/60000]\n",
      "loss: 0.000310 [51232/60000]\n",
      "loss: 0.000896 [54432/60000]\n",
      "loss: 0.000568 [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss:0.097541 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------\")\n",
    "    train(train_data_loader, model, loss_fn, optimizer)\n",
    "    test(test_data_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.99232\n"
     ]
    }
   ],
   "source": [
    "print(f\"Neural network accuracy on train set: {train_acc:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9766\n"
     ]
    }
   ],
   "source": [
    "print(f\"Neural network accuracy on test set: {test_acc:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, \"Test accuracy is below 0.92 threshold\"\n",
    "assert (\n",
    "    train_acc >= 0.91\n",
    "), \"Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Загрузите файл `hw11_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please, download `hw11_data_dict.npy` and place it in the working directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhw11_data_dict.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease, download `hw11_data_dict.npy` and place it in the working directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_predictions\u001b[39m(model, eval_data, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     13\u001b[0m     predicted_labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please, download `hw11_data_dict.npy` and place it in the working directory"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import json\n",
    "\n",
    "assert os.path.exists(\n",
    "    \"hw11_data_dict.npy\"\n",
    "), \"Please, download `hw11_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
    "    predicted_labels = \",\".join([str(x) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "loaded_data_dict = np.load(\"hw11_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train\": get_predictions(\n",
    "        model, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test\": get_predictions(model, torch.FloatTensor(loaded_data_dict.item()[\"test\"])),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_hw11.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_hw11.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw07.npy`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "\n",
    "assert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])).numpy(),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test'])).numpy()\n",
    "}\n",
    "\n",
    "np.save('submission_dict_hw07.npy', submission_dict, allow_pickle=True)\n",
    "print('File saved to `submission_dict_hw07.npy`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
